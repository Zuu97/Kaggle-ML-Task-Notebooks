{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.utils import shuffle\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nnp.random.seed(42)\nTexts = []\nFile_names = []\n\ntext_file_dir = '/kaggle/input'\nfor dirname, _, filenames in os.walk(text_file_dir):\n    if filenames:\n        for filename in filenames:\n            text_file = os.path.join(dirname, filename)\n            File_names.append(filename)\n            with open(text_file) as file:\n               for line in file:\n                  Texts.append(line)  ","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def lemmatization(lemmatizer,sentence):\n    lem = [lemmatizer.lemmatize(k) for k in sentence]\n    lem = set(lem)\n    return [k for k in lem]\n\ndef remove_stop_words(stopwords_list,sentence):\n    return [k for k in sentence if k not in stopwords_list]\n\ndef preprocessed_rallies(rallies):\n    updated_rallies = []\n    for rallie in rallies:\n        lemmatizer = WordNetLemmatizer()\n        tokenizer = RegexpTokenizer(r'\\w+')\n        stopwords_list = stopwords.words('english')\n        rallie = rallie.lower()\n        remove_punc = tokenizer.tokenize(rallie) # Remove puntuations\n        remove_num = [re.sub('[0-9]', '', i) for i in remove_punc] # Remove Numbers\n        remove_num = [i for i in remove_num if len(i)>0] # Remove empty strings\n        lemmatized = lemmatization(lemmatizer,remove_num) # Word Lemmatization\n        remove_stop = remove_stop_words(stopwords_list,lemmatized) # remove stop words\n        updated_rallie = ' '.join(remove_stop)\n        updated_rallies.append(updated_rallie)\n    return np.array(updated_rallies)\n\ndef get_data(Texts):\n    preprocessed_texts = preprocessed_rallies(Texts)\n    return preprocessed_texts","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_texts = get_data(Texts)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(preprocessed_texts)\nvocabulary = vectorizer.get_feature_names()\nprint(\"Input feature shape : {}\".format(X.shape))","execution_count":23,"outputs":[{"output_type":"stream","text":"Input feature shape : (35, 7198)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2, random_state=42)\nkmeans.fit(X)","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"KMeans(n_clusters=2, random_state=42)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiments = kmeans.predict(X)\n\nresults = {\n        'File Name' : File_names,\n        'Sentiments': sentiments\n          }\n\ndf = pd.DataFrame(results) \ndf.to_csv('/kaggle/working/sentiments.csv', index=False)","execution_count":25,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}